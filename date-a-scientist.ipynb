{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üß¨ Date-A-Scientist: OKCupid Data Analysis Project\n",
    "\n",
    "Welcome to your OKCupid data analysis project! This notebook will guide you through analyzing dating app data using machine learning techniques.\n",
    "\n",
    "## üìã Project Overview\n",
    "In this project, you will:\n",
    "- Analyze OKCupid user profiles and preferences\n",
    "- Explore patterns in dating behavior\n",
    "- Build machine learning models to predict user characteristics\n",
    "- Create visualizations to communicate your findings\n",
    "\n",
    "## üéØ Learning Objectives\n",
    "- Practice data exploration and preprocessing\n",
    "- Apply supervised and unsupervised machine learning\n",
    "- Use natural language processing techniques\n",
    "- Communicate findings through visualizations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Libraries imported successfully!\n",
      "üìä Ready to start data analysis!\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully!\")\n",
    "print(\"üìä Ready to start data analysis!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Step 1: Load and Explore the Data\n",
    "\n",
    "First, let's load our OKCupid dataset and get familiar with its structure. This step involves:\n",
    "- Loading the CSV file\n",
    "- Examining the data shape and structure\n",
    "- Understanding column names and data types\n",
    "- Getting basic summary statistics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìà Dataset Shape: (59946, 31)\n",
      "\n",
      "üìã Column Names:\n",
      "['age', 'body_type', 'diet', 'drinks', 'drugs', 'education', 'essay0', 'essay1', 'essay2', 'essay3', 'essay4', 'essay5', 'essay6', 'essay7', 'essay8', 'essay9', 'ethnicity', 'height', 'income', 'job', 'last_online', 'location', 'offspring', 'orientation', 'pets', 'religion', 'sex', 'sign', 'smokes', 'speaks', 'status']\n",
      "\n",
      "üîç Data Types:\n",
      "age              int64\n",
      "body_type       object\n",
      "diet            object\n",
      "drinks          object\n",
      "drugs           object\n",
      "education       object\n",
      "essay0          object\n",
      "essay1          object\n",
      "essay2          object\n",
      "essay3          object\n",
      "essay4          object\n",
      "essay5          object\n",
      "essay6          object\n",
      "essay7          object\n",
      "essay8          object\n",
      "essay9          object\n",
      "ethnicity       object\n",
      "height         float64\n",
      "income           int64\n",
      "job             object\n",
      "last_online     object\n",
      "location        object\n",
      "offspring       object\n",
      "orientation     object\n",
      "pets            object\n",
      "religion        object\n",
      "sex             object\n",
      "sign            object\n",
      "smokes          object\n",
      "speaks          object\n",
      "status          object\n",
      "dtype: object\n",
      "\n",
      "üìä First 5 rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>body_type</th>\n",
       "      <th>diet</th>\n",
       "      <th>drinks</th>\n",
       "      <th>drugs</th>\n",
       "      <th>education</th>\n",
       "      <th>essay0</th>\n",
       "      <th>essay1</th>\n",
       "      <th>essay2</th>\n",
       "      <th>essay3</th>\n",
       "      <th>essay4</th>\n",
       "      <th>essay5</th>\n",
       "      <th>essay6</th>\n",
       "      <th>essay7</th>\n",
       "      <th>essay8</th>\n",
       "      <th>essay9</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>height</th>\n",
       "      <th>income</th>\n",
       "      <th>job</th>\n",
       "      <th>last_online</th>\n",
       "      <th>location</th>\n",
       "      <th>offspring</th>\n",
       "      <th>orientation</th>\n",
       "      <th>pets</th>\n",
       "      <th>religion</th>\n",
       "      <th>sex</th>\n",
       "      <th>sign</th>\n",
       "      <th>smokes</th>\n",
       "      <th>speaks</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>a little extra</td>\n",
       "      <td>strictly anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>working on college/university</td>\n",
       "      <td>about me:&lt;br /&gt;\\n&lt;br /&gt;\\ni would love to think that i was some some kind of intellectual:\\neither the dumbest smart guy, or the smartest dumb guy. can't say i\\ncan tell the difference. i love to talk about ideas and concepts. i\\nforge odd metaphors instead of reciting cliches. like the\\nsimularities between a friend of mine's house and an underwater\\nsalt mine. my favorite word is salt by the way (weird choice i\\nknow). to me most things in life are better as metaphors. i seek to\\nmake myself a little better everyday, in some productively lazy\\nway. got tired of tying my shoes. considered hiring a five year\\nold, but would probably have to tie both of our shoes... decided to\\nonly wear leather shoes dress shoes.&lt;br /&gt;\\n&lt;br /&gt;\\nabout you:&lt;br /&gt;\\n&lt;br /&gt;\\nyou love to have really serious, really deep conversations about\\nreally silly stuff. you have to be willing to snap me out of a\\nlight hearted rant with a kiss. you don't have to be funny, but you\\nhave to be able to make me laugh. you should be able to bend spoons\\nwith your mind, and telepathically make me smile while i am still\\nat work. you should love life, and be cool with just letting the\\nwind blow. extra points for reading all this and guessing my\\nfavorite video game (no hints given yet). and lastly you have a\\ngood attention span.</td>\n",
       "      <td>currently working as an international agent for a freight\\nforwarding company. import, export, domestic you know the\\nworks.&lt;br /&gt;\\nonline classes and trying to better myself in my free time. perhaps\\na hours worth of a good book or a video game on a lazy sunday.</td>\n",
       "      <td>making people laugh.&lt;br /&gt;\\nranting about a good salting.&lt;br /&gt;\\nfinding simplicity in complexity, and complexity in simplicity.</td>\n",
       "      <td>the way i look. i am a six foot half asian, half caucasian mutt. it\\nmakes it tough not to notice me, and for me to blend in.</td>\n",
       "      <td>books:&lt;br /&gt;\\nabsurdistan, the republic, of mice and men (only book that made me\\nwant to cry), catcher in the rye, the prince.&lt;br /&gt;\\n&lt;br /&gt;\\nmovies:&lt;br /&gt;\\ngladiator, operation valkyrie, the producers, down periscope.&lt;br /&gt;\\n&lt;br /&gt;\\nshows:&lt;br /&gt;\\nthe borgia, arrested development, game of thrones, monty\\npython&lt;br /&gt;\\n&lt;br /&gt;\\nmusic:&lt;br /&gt;\\naesop rock, hail mary mallon, george thorogood and the delaware\\ndestroyers, felt&lt;br /&gt;\\n&lt;br /&gt;\\nfood:&lt;br /&gt;\\ni'm down for anything.</td>\n",
       "      <td>food.&lt;br /&gt;\\nwater.&lt;br /&gt;\\ncell phone.&lt;br /&gt;\\nshelter.</td>\n",
       "      <td>duality and humorous things</td>\n",
       "      <td>trying to find someone to hang out with. i am down for anything\\nexcept a club.</td>\n",
       "      <td>i am new to california and looking for someone to wisper my secrets\\nto.</td>\n",
       "      <td>you want to be swept off your feet!&lt;br /&gt;\\nyou are tired of the norm.&lt;br /&gt;\\nyou want to catch a coffee or a bite.&lt;br /&gt;\\nor if you want to talk philosophy.</td>\n",
       "      <td>asian, white</td>\n",
       "      <td>75.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>transportation</td>\n",
       "      <td>2012-06-28-20-30</td>\n",
       "      <td>south san francisco, california</td>\n",
       "      <td>doesn&amp;rsquo;t have kids, but might want them</td>\n",
       "      <td>straight</td>\n",
       "      <td>likes dogs and likes cats</td>\n",
       "      <td>agnosticism and very serious about it</td>\n",
       "      <td>m</td>\n",
       "      <td>gemini</td>\n",
       "      <td>sometimes</td>\n",
       "      <td>english</td>\n",
       "      <td>single</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35</td>\n",
       "      <td>average</td>\n",
       "      <td>mostly other</td>\n",
       "      <td>often</td>\n",
       "      <td>sometimes</td>\n",
       "      <td>working on space camp</td>\n",
       "      <td>i am a chef: this is what that means.&lt;br /&gt;\\n1. i am a workaholic.&lt;br /&gt;\\n2. i love to cook regardless of whether i am at work.&lt;br /&gt;\\n3. i love to drink and eat foods that are probably really bad for\\nme.&lt;br /&gt;\\n4. i love being around people that resemble line 1-3.&lt;br /&gt;\\ni love the outdoors and i am an avid skier. if its snowing i will\\nbe in tahoe at the very least. i am a very confident and friendly.\\ni'm not interested in acting or being a typical guy. i have no time\\nor patience for rediculous acts of territorial pissing. overall i\\nam a very likable easygoing individual. i am very adventurous and\\nalways looking forward to doing new things and hopefully sharing it\\nwith the right person.</td>\n",
       "      <td>dedicating everyday to being an unbelievable badass.</td>\n",
       "      <td>being silly. having ridiculous amonts of fun wherever. being a\\nsmart ass. ohh and i can cook. ;)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>i am die hard christopher moore fan. i don't really watch a lot of\\ntv unless there is humor involved. i am kind of stuck on 90's\\nalternative music. i am pretty much a fan of everything though... i\\ndo need to draw a line at most types of electronica.</td>\n",
       "      <td>delicious porkness in all of its glories.&lt;br /&gt;\\nmy big ass doughboy's sinking into 15 new inches.&lt;br /&gt;\\nmy overly resilient liver.&lt;br /&gt;\\na good sharp knife.&lt;br /&gt;\\nmy ps3... it plays blurays too. ;)&lt;br /&gt;\\nmy over the top energy and my outlook on life... just give me a bag\\nof lemons and see what happens. ;)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>i am very open and will share just about anything.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>white</td>\n",
       "      <td>70.0</td>\n",
       "      <td>80000</td>\n",
       "      <td>hospitality / travel</td>\n",
       "      <td>2012-06-29-21-41</td>\n",
       "      <td>oakland, california</td>\n",
       "      <td>doesn&amp;rsquo;t have kids, but might want them</td>\n",
       "      <td>straight</td>\n",
       "      <td>likes dogs and likes cats</td>\n",
       "      <td>agnosticism but not too serious about it</td>\n",
       "      <td>m</td>\n",
       "      <td>cancer</td>\n",
       "      <td>no</td>\n",
       "      <td>english (fluently), spanish (poorly), french (poorly)</td>\n",
       "      <td>single</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>thin</td>\n",
       "      <td>anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>NaN</td>\n",
       "      <td>graduated from masters program</td>\n",
       "      <td>i'm not ashamed of much, but writing public text on an online\\ndating site makes me pleasantly uncomfortable. i'll try to be as\\nearnest as possible in the noble endeavor of standing naked before\\nthe world.&lt;br /&gt;\\n&lt;br /&gt;\\ni've lived in san francisco for 15 years, and both love it and find\\nmyself frustrated with its deficits. lots of great friends and\\nacquaintances (which increases my apprehension to put anything on\\nthis site), but i'm feeling like meeting some new people that\\naren't just friends of friends. it's okay if you are a friend of a\\nfriend too. chances are, if you make it through the complex\\nfiltering process of multiple choice questions, lifestyle\\nstatistics, photo scanning, and these indulgent blurbs of text\\nwithout moving quickly on to another search result, you are\\nprobably already a cultural peer and at most 2 people removed. at\\nfirst, i thought i should say as little as possible here to avoid\\nyou, but that seems silly.&lt;br /&gt;\\n&lt;br /&gt;\\nas far as culture goes, i'm definitely more on the weird side of\\nthe spectrum, but i don't exactly wear it on my sleeve. once you\\nget me talking, it will probably become increasingly apparent that\\nwhile i'd like to think of myself as just like everybody else (and\\nby some definition i certainly am), most people don't see me that\\nway. that's fine with me. most of the people i find myself\\ngravitating towards are pretty weird themselves. you probably are\\ntoo.</td>\n",
       "      <td>i make nerdy software for musicians, artists, and experimenters to\\nindulge in their own weirdness, but i like to spend time away from\\nthe computer when working on my artwork (which is typically more\\nconcerned with group dynamics and communication, than with visual\\nform, objects, or technology). i also record and deejay dance,\\nnoise, pop, and experimental music (most of which electronic or at\\nleast studio based). besides these relatively ego driven\\nactivities, i've been enjoying things like meditation and tai chi\\nto try and gently flirt with ego death.</td>\n",
       "      <td>improvising in different contexts. alternating between being\\npresent and decidedly outside of a moment, or trying to hold both\\nat once. rambling intellectual conversations that hold said\\nconversations in contempt while seeking to find something that\\ntranscends them. being critical while remaining generous. listening\\nto and using body language--often performed in caricature or large\\ngestures, if not outright interpretive dance. dry, dark, and\\nraunchy humor.</td>\n",
       "      <td>my large jaw and large glasses are the physical things people\\ncomment on the most. when sufficiently stimulated, i have an\\nunmistakable cackle of a laugh. after that, it goes in more\\ndirections than i care to describe right now. maybe i'll come back\\nto this.</td>\n",
       "      <td>okay this is where the cultural matrix gets so specific, it's like\\nbeing in the crosshairs.&lt;br /&gt;\\n&lt;br /&gt;\\nfor what it's worth, i find myself reading more non-fiction than\\nfiction. it's usually some kind of philosophy, art, or science text\\nby silly authors such as ranciere, de certeau, bataille,\\nbaudrillard, butler, stein, arendt, nietzche, zizek, etc. i'll\\noften throw in some weird new age or pop-psychology book in the mix\\nas well. as for fiction, i enjoy what little i've read of eco,\\nperec, wallace, bolao, dick, vonnegut, atwood, delilo, etc. when i\\nwas young, i was a rabid asimov reader.&lt;br /&gt;\\n&lt;br /&gt;\\ndirectors i find myself drawn to are makavejev, kuchar, jodorowsky,\\nherzog, hara, klein, waters, verhoeven, ackerman, hitchcock, lang,\\ngorin, goddard, miike, ohbayashi, tarkovsky, sokurov, warhol, etc.\\nbut i also like a good amount of \"trashy\" stuff. too much to\\nname.&lt;br /&gt;\\n&lt;br /&gt;\\ni definitely enjoy the character development that happens in long\\nform episodic television over the course of 10-100 episodes, which\\na 1-2hr movie usually can't compete with. some of my recent tv\\nfavorites are: breaking bad, the wire, dexter, true blood, the\\nprisoner, lost, fringe.&lt;br /&gt;\\n&lt;br /&gt;\\na smattered sampling of the vast field of music i like and deejay:\\nart ensemble, sun ra, evan parker, lil wayne, dj funk, mr. fingers,\\nmaurizio, rob hood, dan bell, james blake, nonesuch recordings,\\nomar souleyman, ethiopiques, fela kuti, john cage, meredith monk,\\nrobert ashley, terry riley, yoko ono, merzbow, tom tom club, jit,\\njuke, bounce, hyphy, snap, crunk, b'more, kuduro, pop, noise, jazz,\\ntechno, house, acid, new/no wave, (post)punk, etc.&lt;br /&gt;\\n&lt;br /&gt;\\na few of the famous art/dance/theater folk that might locate my\\nsensibility: andy warhol, bruce nauman, yayoi kusama, louise\\nbourgeois, tino sehgal, george kuchar, michel duchamp, marina\\nabramovic, gelatin, carolee schneeman, gustav metzger, mike kelly,\\nmike smith, andrea fraser, gordon matta-clark, jerzy grotowski,\\nsamuel beckett, antonin artaud, tadeusz kantor, anna halperin,\\nmerce cunningham, etc. i'm clearly leaving out a younger generation\\nof contemporary artists, many of whom are friends.&lt;br /&gt;\\n&lt;br /&gt;\\nlocal food regulars: sushi zone, chow, ppq, pagolac, lers ros,\\nburma superstar, minako, shalimar, delfina pizza, rosamunde,\\narinells, suppenkuche, cha-ya, blue plate, golden era, etc.</td>\n",
       "      <td>movement&lt;br /&gt;\\nconversation&lt;br /&gt;\\ncreation&lt;br /&gt;\\ncontemplation&lt;br /&gt;\\ntouch&lt;br /&gt;\\nhumor</td>\n",
       "      <td>NaN</td>\n",
       "      <td>viewing. listening. dancing. talking. drinking. performing.</td>\n",
       "      <td>when i was five years old, i was known as \"the boogerman\".</td>\n",
       "      <td>you are bright, open, intense, silly, ironic, critical, caring,\\ngenerous, looking for an exploration, rather than finding \"a match\"\\nof some predetermined qualities.&lt;br /&gt;\\n&lt;br /&gt;\\ni'm currently in a fabulous and open relationship, so you should be\\ncomfortable with that.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>68.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2012-06-27-09-10</td>\n",
       "      <td>san francisco, california</td>\n",
       "      <td>NaN</td>\n",
       "      <td>straight</td>\n",
       "      <td>has cats</td>\n",
       "      <td>NaN</td>\n",
       "      <td>m</td>\n",
       "      <td>pisces but it doesn&amp;rsquo;t matter</td>\n",
       "      <td>no</td>\n",
       "      <td>english, french, c++</td>\n",
       "      <td>available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23</td>\n",
       "      <td>thin</td>\n",
       "      <td>vegetarian</td>\n",
       "      <td>socially</td>\n",
       "      <td>NaN</td>\n",
       "      <td>working on college/university</td>\n",
       "      <td>i work in a library and go to school. . .</td>\n",
       "      <td>reading things written by old dead people</td>\n",
       "      <td>playing synthesizers and organizing books according to the library\\nof congress classification system</td>\n",
       "      <td>socially awkward but i do my best</td>\n",
       "      <td>bataille, celine, beckett. . .&lt;br /&gt;\\nlynch, jarmusch, r.w. fassbender. . .&lt;br /&gt;\\ntwin peaks &amp;amp; fishing w/ john&lt;br /&gt;\\njoy division, throbbing gristle, cabaret voltaire. . .&lt;br /&gt;\\nvegetarian pho and coffee</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cats and german philosophy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>you feel so inclined.</td>\n",
       "      <td>white</td>\n",
       "      <td>71.0</td>\n",
       "      <td>20000</td>\n",
       "      <td>student</td>\n",
       "      <td>2012-06-28-14-22</td>\n",
       "      <td>berkeley, california</td>\n",
       "      <td>doesn&amp;rsquo;t want kids</td>\n",
       "      <td>straight</td>\n",
       "      <td>likes cats</td>\n",
       "      <td>NaN</td>\n",
       "      <td>m</td>\n",
       "      <td>pisces</td>\n",
       "      <td>no</td>\n",
       "      <td>english, german (poorly)</td>\n",
       "      <td>single</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29</td>\n",
       "      <td>athletic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>graduated from college/university</td>\n",
       "      <td>hey how's it going? currently vague on the profile i know, more to\\ncome soon. looking to meet new folks outside of my circle of\\nfriends. i'm pretty responsive on the reply tip, feel free to drop\\na line. cheers.</td>\n",
       "      <td>work work work work + play</td>\n",
       "      <td>creating imagery to look at:&lt;br /&gt;\\nhttp://bagsbrown.blogspot.com/&lt;br /&gt;\\nhttp://stayruly.blogspot.com/</td>\n",
       "      <td>i smile a lot and my inquisitive nature</td>\n",
       "      <td>music: bands, rappers, musicians&lt;br /&gt;\\nat the moment: thee oh sees.&lt;br /&gt;\\nforever: wu-tang&lt;br /&gt;\\nbooks: artbooks for days&lt;br /&gt;\\naudiobooks: my collection, thick (thanks audible)&lt;br /&gt;\\nshows: live ones&lt;br /&gt;\\nfood: with stellar friends whenever&lt;br /&gt;\\nmovies &amp;gt; tv&lt;br /&gt;\\npodcast: radiolab, this american life, the moth, joe rogan, the\\nchamps</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>asian, black, other</td>\n",
       "      <td>66.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>artistic / musical / writer</td>\n",
       "      <td>2012-06-27-21-26</td>\n",
       "      <td>san francisco, california</td>\n",
       "      <td>NaN</td>\n",
       "      <td>straight</td>\n",
       "      <td>likes dogs and likes cats</td>\n",
       "      <td>NaN</td>\n",
       "      <td>m</td>\n",
       "      <td>aquarius</td>\n",
       "      <td>no</td>\n",
       "      <td>english</td>\n",
       "      <td>single</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age       body_type               diet    drinks      drugs  \\\n",
       "0   22  a little extra  strictly anything  socially      never   \n",
       "1   35         average       mostly other     often  sometimes   \n",
       "2   38            thin           anything  socially        NaN   \n",
       "3   23            thin         vegetarian  socially        NaN   \n",
       "4   29        athletic                NaN  socially      never   \n",
       "\n",
       "                           education  \\\n",
       "0      working on college/university   \n",
       "1              working on space camp   \n",
       "2     graduated from masters program   \n",
       "3      working on college/university   \n",
       "4  graduated from college/university   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              essay0  \\\n",
       "0                                                                                                                                    about me:<br />\\n<br />\\ni would love to think that i was some some kind of intellectual:\\neither the dumbest smart guy, or the smartest dumb guy. can't say i\\ncan tell the difference. i love to talk about ideas and concepts. i\\nforge odd metaphors instead of reciting cliches. like the\\nsimularities between a friend of mine's house and an underwater\\nsalt mine. my favorite word is salt by the way (weird choice i\\nknow). to me most things in life are better as metaphors. i seek to\\nmake myself a little better everyday, in some productively lazy\\nway. got tired of tying my shoes. considered hiring a five year\\nold, but would probably have to tie both of our shoes... decided to\\nonly wear leather shoes dress shoes.<br />\\n<br />\\nabout you:<br />\\n<br />\\nyou love to have really serious, really deep conversations about\\nreally silly stuff. you have to be willing to snap me out of a\\nlight hearted rant with a kiss. you don't have to be funny, but you\\nhave to be able to make me laugh. you should be able to bend spoons\\nwith your mind, and telepathically make me smile while i am still\\nat work. you should love life, and be cool with just letting the\\nwind blow. extra points for reading all this and guessing my\\nfavorite video game (no hints given yet). and lastly you have a\\ngood attention span.   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    i am a chef: this is what that means.<br />\\n1. i am a workaholic.<br />\\n2. i love to cook regardless of whether i am at work.<br />\\n3. i love to drink and eat foods that are probably really bad for\\nme.<br />\\n4. i love being around people that resemble line 1-3.<br />\\ni love the outdoors and i am an avid skier. if its snowing i will\\nbe in tahoe at the very least. i am a very confident and friendly.\\ni'm not interested in acting or being a typical guy. i have no time\\nor patience for rediculous acts of territorial pissing. overall i\\nam a very likable easygoing individual. i am very adventurous and\\nalways looking forward to doing new things and hopefully sharing it\\nwith the right person.   \n",
       "2  i'm not ashamed of much, but writing public text on an online\\ndating site makes me pleasantly uncomfortable. i'll try to be as\\nearnest as possible in the noble endeavor of standing naked before\\nthe world.<br />\\n<br />\\ni've lived in san francisco for 15 years, and both love it and find\\nmyself frustrated with its deficits. lots of great friends and\\nacquaintances (which increases my apprehension to put anything on\\nthis site), but i'm feeling like meeting some new people that\\naren't just friends of friends. it's okay if you are a friend of a\\nfriend too. chances are, if you make it through the complex\\nfiltering process of multiple choice questions, lifestyle\\nstatistics, photo scanning, and these indulgent blurbs of text\\nwithout moving quickly on to another search result, you are\\nprobably already a cultural peer and at most 2 people removed. at\\nfirst, i thought i should say as little as possible here to avoid\\nyou, but that seems silly.<br />\\n<br />\\nas far as culture goes, i'm definitely more on the weird side of\\nthe spectrum, but i don't exactly wear it on my sleeve. once you\\nget me talking, it will probably become increasingly apparent that\\nwhile i'd like to think of myself as just like everybody else (and\\nby some definition i certainly am), most people don't see me that\\nway. that's fine with me. most of the people i find myself\\ngravitating towards are pretty weird themselves. you probably are\\ntoo.   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          i work in a library and go to school. . .   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              hey how's it going? currently vague on the profile i know, more to\\ncome soon. looking to meet new folks outside of my circle of\\nfriends. i'm pretty responsive on the reply tip, feel free to drop\\na line. cheers.   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  essay1  \\\n",
       "0                                                                                                                                                                                                                                                                                                                currently working as an international agent for a freight\\nforwarding company. import, export, domestic you know the\\nworks.<br />\\nonline classes and trying to better myself in my free time. perhaps\\na hours worth of a good book or a video game on a lazy sunday.   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   dedicating everyday to being an unbelievable badass.   \n",
       "2  i make nerdy software for musicians, artists, and experimenters to\\nindulge in their own weirdness, but i like to spend time away from\\nthe computer when working on my artwork (which is typically more\\nconcerned with group dynamics and communication, than with visual\\nform, objects, or technology). i also record and deejay dance,\\nnoise, pop, and experimental music (most of which electronic or at\\nleast studio based). besides these relatively ego driven\\nactivities, i've been enjoying things like meditation and tai chi\\nto try and gently flirt with ego death.   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              reading things written by old dead people   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             work work work work + play   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                essay2  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                     making people laugh.<br />\\nranting about a good salting.<br />\\nfinding simplicity in complexity, and complexity in simplicity.   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                    being silly. having ridiculous amonts of fun wherever. being a\\nsmart ass. ohh and i can cook. ;)   \n",
       "2  improvising in different contexts. alternating between being\\npresent and decidedly outside of a moment, or trying to hold both\\nat once. rambling intellectual conversations that hold said\\nconversations in contempt while seeking to find something that\\ntranscends them. being critical while remaining generous. listening\\nto and using body language--often performed in caricature or large\\ngestures, if not outright interpretive dance. dry, dark, and\\nraunchy humor.   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                playing synthesizers and organizing books according to the library\\nof congress classification system   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                              creating imagery to look at:<br />\\nhttp://bagsbrown.blogspot.com/<br />\\nhttp://stayruly.blogspot.com/   \n",
       "\n",
       "                                                                                                                                                                                                                                                                   essay3  \\\n",
       "0                                                                                                                                           the way i look. i am a six foot half asian, half caucasian mutt. it\\nmakes it tough not to notice me, and for me to blend in.   \n",
       "1                                                                                                                                                                                                                                                                     NaN   \n",
       "2  my large jaw and large glasses are the physical things people\\ncomment on the most. when sufficiently stimulated, i have an\\nunmistakable cackle of a laugh. after that, it goes in more\\ndirections than i care to describe right now. maybe i'll come back\\nto this.   \n",
       "3                                                                                                                                                                                                                                       socially awkward but i do my best   \n",
       "4                                                                                                                                                                                                                                 i smile a lot and my inquisitive nature   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  essay4  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            books:<br />\\nabsurdistan, the republic, of mice and men (only book that made me\\nwant to cry), catcher in the rye, the prince.<br />\\n<br />\\nmovies:<br />\\ngladiator, operation valkyrie, the producers, down periscope.<br />\\n<br />\\nshows:<br />\\nthe borgia, arrested development, game of thrones, monty\\npython<br />\\n<br />\\nmusic:<br />\\naesop rock, hail mary mallon, george thorogood and the delaware\\ndestroyers, felt<br />\\n<br />\\nfood:<br />\\ni'm down for anything.   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           i am die hard christopher moore fan. i don't really watch a lot of\\ntv unless there is humor involved. i am kind of stuck on 90's\\nalternative music. i am pretty much a fan of everything though... i\\ndo need to draw a line at most types of electronica.   \n",
       "2  okay this is where the cultural matrix gets so specific, it's like\\nbeing in the crosshairs.<br />\\n<br />\\nfor what it's worth, i find myself reading more non-fiction than\\nfiction. it's usually some kind of philosophy, art, or science text\\nby silly authors such as ranciere, de certeau, bataille,\\nbaudrillard, butler, stein, arendt, nietzche, zizek, etc. i'll\\noften throw in some weird new age or pop-psychology book in the mix\\nas well. as for fiction, i enjoy what little i've read of eco,\\nperec, wallace, bolao, dick, vonnegut, atwood, delilo, etc. when i\\nwas young, i was a rabid asimov reader.<br />\\n<br />\\ndirectors i find myself drawn to are makavejev, kuchar, jodorowsky,\\nherzog, hara, klein, waters, verhoeven, ackerman, hitchcock, lang,\\ngorin, goddard, miike, ohbayashi, tarkovsky, sokurov, warhol, etc.\\nbut i also like a good amount of \"trashy\" stuff. too much to\\nname.<br />\\n<br />\\ni definitely enjoy the character development that happens in long\\nform episodic television over the course of 10-100 episodes, which\\na 1-2hr movie usually can't compete with. some of my recent tv\\nfavorites are: breaking bad, the wire, dexter, true blood, the\\nprisoner, lost, fringe.<br />\\n<br />\\na smattered sampling of the vast field of music i like and deejay:\\nart ensemble, sun ra, evan parker, lil wayne, dj funk, mr. fingers,\\nmaurizio, rob hood, dan bell, james blake, nonesuch recordings,\\nomar souleyman, ethiopiques, fela kuti, john cage, meredith monk,\\nrobert ashley, terry riley, yoko ono, merzbow, tom tom club, jit,\\njuke, bounce, hyphy, snap, crunk, b'more, kuduro, pop, noise, jazz,\\ntechno, house, acid, new/no wave, (post)punk, etc.<br />\\n<br />\\na few of the famous art/dance/theater folk that might locate my\\nsensibility: andy warhol, bruce nauman, yayoi kusama, louise\\nbourgeois, tino sehgal, george kuchar, michel duchamp, marina\\nabramovic, gelatin, carolee schneeman, gustav metzger, mike kelly,\\nmike smith, andrea fraser, gordon matta-clark, jerzy grotowski,\\nsamuel beckett, antonin artaud, tadeusz kantor, anna halperin,\\nmerce cunningham, etc. i'm clearly leaving out a younger generation\\nof contemporary artists, many of whom are friends.<br />\\n<br />\\nlocal food regulars: sushi zone, chow, ppq, pagolac, lers ros,\\nburma superstar, minako, shalimar, delfina pizza, rosamunde,\\narinells, suppenkuche, cha-ya, blue plate, golden era, etc.   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     bataille, celine, beckett. . .<br />\\nlynch, jarmusch, r.w. fassbender. . .<br />\\ntwin peaks &amp; fishing w/ john<br />\\njoy division, throbbing gristle, cabaret voltaire. . .<br />\\nvegetarian pho and coffee   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          music: bands, rappers, musicians<br />\\nat the moment: thee oh sees.<br />\\nforever: wu-tang<br />\\nbooks: artbooks for days<br />\\naudiobooks: my collection, thick (thanks audible)<br />\\nshows: live ones<br />\\nfood: with stellar friends whenever<br />\\nmovies &gt; tv<br />\\npodcast: radiolab, this american life, the moth, joe rogan, the\\nchamps   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                     essay5  \\\n",
       "0                                                                                                                                                                                                                                                                    food.<br />\\nwater.<br />\\ncell phone.<br />\\nshelter.   \n",
       "1  delicious porkness in all of its glories.<br />\\nmy big ass doughboy's sinking into 15 new inches.<br />\\nmy overly resilient liver.<br />\\na good sharp knife.<br />\\nmy ps3... it plays blurays too. ;)<br />\\nmy over the top energy and my outlook on life... just give me a bag\\nof lemons and see what happens. ;)   \n",
       "2                                                                                                                                                                                                                               movement<br />\\nconversation<br />\\ncreation<br />\\ncontemplation<br />\\ntouch<br />\\nhumor   \n",
       "3                                                                                                                                                                                                                                                                                                                       NaN   \n",
       "4                                                                                                                                                                                                                                                                                                                       NaN   \n",
       "\n",
       "                        essay6  \\\n",
       "0  duality and humorous things   \n",
       "1                          NaN   \n",
       "2                          NaN   \n",
       "3   cats and german philosophy   \n",
       "4                          NaN   \n",
       "\n",
       "                                                                            essay7  \\\n",
       "0  trying to find someone to hang out with. i am down for anything\\nexcept a club.   \n",
       "1                                                                              NaN   \n",
       "2                      viewing. listening. dancing. talking. drinking. performing.   \n",
       "3                                                                              NaN   \n",
       "4                                                                              NaN   \n",
       "\n",
       "                                                                     essay8  \\\n",
       "0  i am new to california and looking for someone to wisper my secrets\\nto.   \n",
       "1                        i am very open and will share just about anything.   \n",
       "2                when i was five years old, i was known as \"the boogerman\".   \n",
       "3                                                                       NaN   \n",
       "4                                                                       NaN   \n",
       "\n",
       "                                                                                                                                                                                                                                                                              essay9  \\\n",
       "0                                                                                                                       you want to be swept off your feet!<br />\\nyou are tired of the norm.<br />\\nyou want to catch a coffee or a bite.<br />\\nor if you want to talk philosophy.   \n",
       "1                                                                                                                                                                                                                                                                                NaN   \n",
       "2  you are bright, open, intense, silly, ironic, critical, caring,\\ngenerous, looking for an exploration, rather than finding \"a match\"\\nof some predetermined qualities.<br />\\n<br />\\ni'm currently in a fabulous and open relationship, so you should be\\ncomfortable with that.   \n",
       "3                                                                                                                                                                                                                                                              you feel so inclined.   \n",
       "4                                                                                                                                                                                                                                                                                NaN   \n",
       "\n",
       "             ethnicity  height  income                          job  \\\n",
       "0         asian, white    75.0      -1               transportation   \n",
       "1                white    70.0   80000         hospitality / travel   \n",
       "2                  NaN    68.0      -1                          NaN   \n",
       "3                white    71.0   20000                      student   \n",
       "4  asian, black, other    66.0      -1  artistic / musical / writer   \n",
       "\n",
       "        last_online                         location  \\\n",
       "0  2012-06-28-20-30  south san francisco, california   \n",
       "1  2012-06-29-21-41              oakland, california   \n",
       "2  2012-06-27-09-10        san francisco, california   \n",
       "3  2012-06-28-14-22             berkeley, california   \n",
       "4  2012-06-27-21-26        san francisco, california   \n",
       "\n",
       "                                      offspring orientation  \\\n",
       "0  doesn&rsquo;t have kids, but might want them    straight   \n",
       "1  doesn&rsquo;t have kids, but might want them    straight   \n",
       "2                                           NaN    straight   \n",
       "3                       doesn&rsquo;t want kids    straight   \n",
       "4                                           NaN    straight   \n",
       "\n",
       "                        pets                                  religion sex  \\\n",
       "0  likes dogs and likes cats     agnosticism and very serious about it   m   \n",
       "1  likes dogs and likes cats  agnosticism but not too serious about it   m   \n",
       "2                   has cats                                       NaN   m   \n",
       "3                 likes cats                                       NaN   m   \n",
       "4  likes dogs and likes cats                                       NaN   m   \n",
       "\n",
       "                                 sign     smokes  \\\n",
       "0                              gemini  sometimes   \n",
       "1                              cancer         no   \n",
       "2  pisces but it doesn&rsquo;t matter         no   \n",
       "3                              pisces         no   \n",
       "4                            aquarius         no   \n",
       "\n",
       "                                                  speaks     status  \n",
       "0                                                english     single  \n",
       "1  english (fluently), spanish (poorly), french (poorly)     single  \n",
       "2                                   english, french, c++  available  \n",
       "3                               english, german (poorly)     single  \n",
       "4                                                english     single  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('profiles.csv')\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# Basic information about the dataset\n",
    "print(\"üìà Dataset Shape:\", df.shape)\n",
    "print(\"\\nüìã Column Names:\")\n",
    "print(df.columns.tolist())\n",
    "print(\"\\nüîç Data Types:\")\n",
    "print(df.dtypes)\n",
    "print(\"\\nüìä First 5 rows:\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç ALL Data Types (Complete List):\n",
      "==================================================\n",
      " 1. age                  int64\n",
      " 2. body_type            object\n",
      " 3. diet                 object\n",
      " 4. drinks               object\n",
      " 5. drugs                object\n",
      " 6. education            object\n",
      " 7. essay0               object\n",
      " 8. essay1               object\n",
      " 9. essay2               object\n",
      "10. essay3               object\n",
      "11. essay4               object\n",
      "12. essay5               object\n",
      "13. essay6               object\n",
      "14. essay7               object\n",
      "15. essay8               object\n",
      "16. essay9               object\n",
      "17. ethnicity            object\n",
      "18. height               float64\n",
      "19. income               int64\n",
      "20. job                  object\n",
      "21. last_online          object\n",
      "22. location             object\n",
      "23. offspring            object\n",
      "24. orientation          object\n",
      "25. pets                 object\n",
      "26. religion             object\n",
      "27. sex                  object\n",
      "28. sign                 object\n",
      "29. smokes               object\n",
      "30. speaks               object\n",
      "31. status               object\n",
      "\n",
      "üìä Total columns: 31\n",
      "\n",
      "üìã Column Information Table:\n",
      "==================================================\n",
      "                  Column Data_Type  Non_Null_Count  Null_Count  Unique_Values\n",
      "age                  age     int64           59946           0             54\n",
      "body_type      body_type    object           54650        5296             12\n",
      "diet                diet    object           35551       24395             18\n",
      "drinks            drinks    object           56961        2985              6\n",
      "drugs              drugs    object           45866       14080              3\n",
      "education      education    object           53318        6628             32\n",
      "essay0            essay0    object           54458        5488          54350\n",
      "essay1            essay1    object           52374        7572          51516\n",
      "essay2            essay2    object           50308        9638          48635\n",
      "essay3            essay3    object           48470       11476          43533\n",
      "essay4            essay4    object           49409       10537          49260\n",
      "essay5            essay5    object           49096       10850          48963\n",
      "essay6            essay6    object           46175       13771          43603\n",
      "essay7            essay7    object           47495       12451          45554\n",
      "essay8            essay8    object           40721       19225          39324\n",
      "essay9            essay9    object           47343       12603          45443\n",
      "ethnicity      ethnicity    object           54266        5680            217\n",
      "height            height   float64           59943           3             60\n",
      "income            income     int64           59946           0             13\n",
      "job                  job    object           51748        8198             21\n",
      "last_online  last_online    object           59946           0          30123\n",
      "location        location    object           59946           0            199\n",
      "offspring      offspring    object           24385       35561             15\n",
      "orientation  orientation    object           59946           0              3\n",
      "pets                pets    object           40025       19921             15\n",
      "religion        religion    object           39720       20226             45\n",
      "sex                  sex    object           59946           0              2\n",
      "sign                sign    object           48890       11056             48\n",
      "smokes            smokes    object           54434        5512              5\n",
      "speaks            speaks    object           59896          50           7647\n",
      "status            status    object           59946           0              5\n"
     ]
    }
   ],
   "source": [
    "# Display all columns and data types without truncation\n",
    "print(\"üîç ALL Data Types (Complete List):\")  # Print header for data types section\n",
    "print(\"=\" * 50)  # Print a separator line with 50 equal signs\n",
    "\n",
    "# Method 1: Use pd.set_option to display all columns\n",
    "pd.set_option('display.max_columns', None)  # Set pandas to display all columns (no limit)\n",
    "pd.set_option('display.width', None)  # Set pandas to use unlimited width for display\n",
    "pd.set_option('display.max_colwidth', None)  # Set pandas to show full column content without truncation\n",
    "\n",
    "# Now display all data types\n",
    "for i, (col, dtype) in enumerate(df.dtypes.items(), 1):  # Loop through each column and its data type, starting count at 1\n",
    "    print(f\"{i:2d}. {col:<20} {dtype}\")  # Print column number (2 digits), column name (left-aligned, 20 chars), and data type\n",
    "\n",
    "print(f\"\\nüìä Total columns: {len(df.columns)}\")  # Print the total number of columns in the dataframe\n",
    "\n",
    "# Method 2: Alternative - create a nice dataframe\n",
    "print(\"\\nüìã Column Information Table:\")  # Print header for the detailed column information table\n",
    "print(\"=\" * 50)  # Print another separator line\n",
    "col_info = pd.DataFrame({  # Create a new dataframe with comprehensive column information\n",
    "    'Column': df.columns,  # Get all column names from the original dataframe\n",
    "    'Data_Type': df.dtypes,  # Get the data type for each column\n",
    "    'Non_Null_Count': df.count(),  # Count non-null values in each column\n",
    "    'Null_Count': df.isnull().sum(),  # Count null/missing values in each column\n",
    "    'Unique_Values': df.nunique()  # Count unique values in each column\n",
    "})\n",
    "print(col_info)  # Display the comprehensive column information table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç Step 2: Data Quality Assessment\n",
    "\n",
    "Now let's assess the quality of our data by:\n",
    "- Checking for missing values\n",
    "- Identifying data inconsistencies\n",
    "- Understanding the distribution of key variables\n",
    "- Looking for outliers or unusual patterns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üö® Missing Values Analysis:\n",
      "            Missing Count  Missing Percentage\n",
      "offspring           35561           59.321723\n",
      "diet                24395           40.694959\n",
      "religion            20226           33.740366\n",
      "pets                19921           33.231575\n",
      "essay8              19225           32.070530\n",
      "drugs               14080           23.487806\n",
      "essay6              13771           22.972342\n",
      "essay9              12603           21.023922\n",
      "essay7              12451           20.770360\n",
      "essay3              11476           19.143896\n",
      "sign                11056           18.443266\n",
      "new_zodiac          11056           18.443266\n",
      "essay5              10850           18.099623\n",
      "essay4              10537           17.577486\n",
      "essay2               9638           16.077803\n",
      "job                  8198           13.675641\n",
      "essay1               7572           12.631368\n",
      "education            6628           11.056618\n",
      "ethnicity            5680            9.475194\n",
      "smokes               5512            9.194942\n",
      "essay0               5488            9.154906\n",
      "body_type            5296            8.834618\n",
      "drinks               2985            4.979482\n",
      "speaks                 50            0.083408\n",
      "height                  3            0.005005\n",
      "\n",
      "üìä Numerical Columns Summary:\n",
      "                age        height          income\n",
      "count  59946.000000  59943.000000    59946.000000\n",
      "mean      32.340290     68.295281    20033.222534\n",
      "std        9.452779      3.994803    97346.192104\n",
      "min       18.000000      1.000000       -1.000000\n",
      "25%       26.000000     66.000000       -1.000000\n",
      "50%       30.000000     68.000000       -1.000000\n",
      "75%       37.000000     71.000000       -1.000000\n",
      "max      110.000000     95.000000  1000000.000000\n",
      "\n",
      "üè∑Ô∏è Categorical Columns Info:\n",
      "\n",
      "body_type: 12 unique values\n",
      "Top values: {'average': 14652, 'fit': 12711, 'athletic': 11819, 'thin': 4711, 'curvy': 3924, 'a little extra': 2629, 'skinny': 1777, 'full figured': 1009, 'overweight': 444, 'jacked': 421, 'used up': 355, 'rather not say': 198}\n",
      "\n",
      "diet: 18 unique values\n",
      "Top values: {'mostly anything': 16585, 'anything': 6183, 'strictly anything': 5113, 'mostly vegetarian': 3444, 'mostly other': 1007, 'strictly vegetarian': 875, 'vegetarian': 667, 'strictly other': 452, 'mostly vegan': 338, 'other': 331, 'strictly vegan': 228, 'vegan': 136}\n",
      "\n",
      "drinks: 6 unique values\n",
      "Top values: {'socially': 41780, 'rarely': 5957, 'often': 5164, 'not at all': 3267, 'very often': 471, 'desperately': 322}\n",
      "\n",
      "drugs: 3 unique values\n",
      "Top values: {'never': 37724, 'sometimes': 7732, 'often': 410}\n",
      "\n",
      "education: 32 unique values\n",
      "Top values: {'graduated from college/university': 23959, 'graduated from masters program': 8961, 'working on college/university': 5712, 'working on masters program': 1683, 'graduated from two-year college': 1531, 'graduated from high school': 1428, 'graduated from ph.d program': 1272, 'graduated from law school': 1122, 'working on two-year college': 1074, 'dropped out of college/university': 995, 'working on ph.d program': 983, 'college/university': 801}\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(\"üö® Missing Values Analysis:\")\n",
    "missing_data = df.isnull().sum()\n",
    "missing_percentage = (missing_data / len(df)) * 100\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing Count': missing_data,\n",
    "    'Missing Percentage': missing_percentage\n",
    "})\n",
    "print(missing_df[missing_df['Missing Count'] > 0].sort_values('Missing Count', ascending=False))\n",
    "\n",
    "# Basic statistics for numerical columns\n",
    "print(\"\\nüìä Numerical Columns Summary:\")\n",
    "print(df.describe())\n",
    "\n",
    "# Check unique values in categorical columns\n",
    "print(\"\\nüè∑Ô∏è Categorical Columns Info:\")\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "for col in categorical_cols[:5]:  # Show first 5 categorical columns\n",
    "    print(f\"\\n{col}: {df[col].nunique()} unique values\")\n",
    "    print(f\"Top values: {df[col].value_counts().head(12).to_dict()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of essays that are not completed are:\n",
      "essay0     5488\n",
      "essay1     7572\n",
      "essay2     9638\n",
      "essay3    11476\n",
      "essay4    10537\n",
      "essay5    10850\n",
      "essay6    13771\n",
      "essay7    12451\n",
      "essay8    19225\n",
      "essay9    12603\n",
      "dtype: int64\n",
      "The total of essays without being filled is 113611 that is the 18.95%\n",
      "At least 57822 have 1 essay filled out\n",
      "\n",
      "The total number of people that filled out all the essays is 29866\n",
      "The essay essay0 is the most completed one with 54458\n",
      "\n",
      "The essay essay8 is the least completed one with 40721\n",
      "\n",
      "Essays with most fields filled in descending order:\n",
      "essay0    54458\n",
      "essay1    52374\n",
      "essay2    50308\n",
      "essay4    49409\n",
      "essay5    49096\n",
      "essay3    48470\n",
      "essay7    47495\n",
      "essay9    47343\n",
      "essay6    46175\n",
      "essay8    40721\n",
      "dtype: int64\n",
      "Relation of essays per sign:  \n",
      "              essay0  essay1  essay2  essay3  essay4  essay5  essay6  essay7  \\\n",
      "new_zodiac                                                                    \n",
      "aquarius       3576    3478    3365    3235    3272    3290    3117    3151   \n",
      "aries          3673    3568    3445    3315    3377    3392    3202    3318   \n",
      "cancer         3830    3712    3582    3526    3535    3536    3318    3415   \n",
      "capricorn      3258    3152    3078    2994    2997    3026    2837    2940   \n",
      "gemini         3968    3834    3692    3585    3650    3637    3420    3530   \n",
      "leo            4009    3910    3772    3640    3711    3679    3501    3572   \n",
      "libra          3870    3767    3652    3577    3583    3582    3388    3487   \n",
      "pisces         3614    3513    3394    3306    3323    3331    3155    3245   \n",
      "sagittarius    3629    3513    3399    3320    3378    3329    3169    3234   \n",
      "scorpio        3781    3626    3502    3410    3455    3451    3251    3342   \n",
      "taurus         3784    3709    3588    3443    3527    3518    3296    3425   \n",
      "virgo          3804    3682    3572    3477    3493    3521    3314    3409   \n",
      "\n",
      "             essay8  essay9  \n",
      "new_zodiac                   \n",
      "aquarius       2723    3152  \n",
      "aries          2841    3249  \n",
      "cancer         2985    3411  \n",
      "capricorn      2496    2891  \n",
      "gemini         3031    3526  \n",
      "leo            3074    3526  \n",
      "libra          3030    3472  \n",
      "pisces         2810    3205  \n",
      "sagittarius    2843    3190  \n",
      "scorpio        2905    3335  \n",
      "taurus         2927    3380  \n",
      "virgo          2953    3363  \n",
      "The number of people per each sign: \n",
      " new_zodiac\n",
      "aquarius       3928\n",
      "aries          3989\n",
      "cancer         4206\n",
      "capricorn      3573\n",
      "gemini         4310\n",
      "leo            4374\n",
      "libra          4207\n",
      "pisces         3946\n",
      "sagittarius    3942\n",
      "scorpio        4134\n",
      "taurus         4140\n",
      "virgo          4141\n",
      "dtype: int64 \n",
      "\n",
      "The number of essays per sign in descending order is: new_zodiac\n",
      "leo            36394\n",
      "gemini         35873\n",
      "libra          35408\n",
      "cancer         34850\n",
      "taurus         34597\n",
      "virgo          34588\n",
      "scorpio        34058\n",
      "aries          33380\n",
      "sagittarius    33004\n",
      "pisces         32896\n",
      "aquarius       32359\n",
      "capricorn      29669\n",
      "dtype: int64 \n",
      "\n",
      "The average number of essays per person by sign is: \n",
      " new_zodiac\n",
      "libra          8.416449\n",
      "sagittarius    8.372400\n",
      "aries          8.368012\n",
      "taurus         8.356763\n",
      "virgo          8.352572\n",
      "pisces         8.336543\n",
      "gemini         8.323202\n",
      "leo            8.320530\n",
      "capricorn      8.303666\n",
      "cancer         8.285782\n",
      "scorpio        8.238510\n",
      "aquarius       8.238035\n",
      "dtype: float64\n",
      "Number of person per sign that drink desperately: 322\n",
      "['socially' 'often' 'not at all' 'rarely' nan 'very often' 'desperately']\n",
      "Dont drink: new_zodiac\n",
      "virgo          260\n",
      "leo            252\n",
      "gemini         249\n",
      "cancer         241\n",
      "scorpio        235\n",
      "libra          233\n",
      "aquarius       227\n",
      "aries          226\n",
      "sagittarius    223\n",
      "taurus         223\n",
      "capricorn      209\n",
      "pisces         192\n",
      "dtype: int64\n",
      "Drink a lot: new_zodiac\n",
      "cancer         27\n",
      "libra          23\n",
      "sagittarius    22\n",
      "capricorn      21\n",
      "gemini         21\n",
      "leo            21\n",
      "scorpio        20\n",
      "aquarius       19\n",
      "taurus         18\n",
      "virgo          18\n",
      "aries          17\n",
      "pisces         16\n",
      "dtype: int64\n",
      "people who never do drugs: new_zodiac\n",
      "leo            2699\n",
      "gemini         2673\n",
      "libra          2615\n",
      "cancer         2612\n",
      "virgo          2609\n",
      "scorpio        2588\n",
      "taurus         2543\n",
      "aries          2495\n",
      "sagittarius    2449\n",
      "aquarius       2425\n",
      "pisces         2420\n",
      "capricorn      2289\n",
      "dtype: int64\n",
      "People that often do drugs: new_zodiac\n",
      "leo            37\n",
      "scorpio        35\n",
      "taurus         33\n",
      "virgo          32\n",
      "gemini         31\n",
      "libra          31\n",
      "capricorn      26\n",
      "cancer         25\n",
      "aquarius       24\n",
      "aries          23\n",
      "pisces         23\n",
      "sagittarius    23\n",
      "dtype: int64\n",
      "['age', 'body_type', 'diet', 'drinks', 'drugs', 'education', 'essay0', 'essay1', 'essay2', 'essay3', 'essay4', 'essay5', 'essay6', 'essay7', 'essay8', 'essay9', 'ethnicity', 'height', 'income', 'job', 'last_online', 'location', 'offspring', 'orientation', 'pets', 'religion', 'sex', 'sign', 'smokes', 'speaks', 'status', 'new_zodiac']\n",
      "PhD and sign: new_zodiac\n",
      "aquarius       70\n",
      "aries          87\n",
      "cancer         75\n",
      "capricorn      58\n",
      "gemini         70\n",
      "leo            83\n",
      "libra          73\n",
      "pisces         90\n",
      "sagittarius    55\n",
      "scorpio        82\n",
      "taurus         72\n",
      "virgo          64\n",
      "dtype: int64\n",
      "Relationship between sign and education: new_zodiac   education                        \n",
      "aquarius     graduated from college/university    1606\n",
      "             graduated from masters program        572\n",
      "             working on college/university         422\n",
      "             graduated from two-year college       113\n",
      "             working on masters program            109\n",
      "             graduated from high school            104\n",
      "             dropped out of college/university      85\n",
      "             working on two-year college            85\n",
      "             graduated from law school              77\n",
      "             graduated from ph.d program            70\n",
      "             working on ph.d program                52\n",
      "             college/university                     47\n",
      "             graduated from space camp              44\n",
      "             dropped out of space camp              43\n",
      "             working on space camp                  25\n",
      "             graduated from med school              23\n",
      "             two-year college                       15\n",
      "             working on law school                  15\n",
      "             dropped out of two-year college        13\n",
      "             masters program                        13\n",
      "             working on med school                  12\n",
      "             high school                            11\n",
      "             dropped out of masters program          9\n",
      "             dropped out of ph.d program             9\n",
      "             dropped out of high school              6\n",
      "             working on high school                  5\n",
      "             dropped out of law school               3\n",
      "             space camp                              3\n",
      "             law school                              2\n",
      "             dropped out of med school               1\n",
      "             med school                              1\n",
      "aries        graduated from college/university    1611\n",
      "             graduated from masters program        579\n",
      "             working on college/university         405\n",
      "             graduated from two-year college       132\n",
      "             working on masters program            110\n",
      "             graduated from high school            107\n",
      "             graduated from ph.d program            87\n",
      "             working on two-year college            77\n",
      "             graduated from law school              67\n",
      "             dropped out of college/university      66\n",
      "             college/university                     64\n",
      "             working on ph.d program                50\n",
      "             graduated from space camp              44\n",
      "             graduated from med school              34\n",
      "             dropped out of space camp              31\n",
      "             working on space camp                  28\n",
      "             working on law school                  18\n",
      "             dropped out of masters program         14\n",
      "             working on med school                  14\n",
      "             dropped out of two-year college        11\n",
      "             two-year college                       11\n",
      "             high school                             6\n",
      "             masters program                         6\n",
      "             working on high school                  6\n",
      "             dropped out of high school              5\n",
      "             dropped out of ph.d program             5\n",
      "             dropped out of med school               4\n",
      "             space camp                              3\n",
      "             law school                              2\n",
      "             med school                              1\n",
      "             ph.d program                            1\n",
      "cancer       graduated from college/university    1716\n",
      "             graduated from masters program        642\n",
      "             working on college/university         453\n",
      "             graduated from two-year college       134\n",
      "             graduated from high school            123\n",
      "             working on masters program            114\n",
      "             working on two-year college            85\n",
      "             graduated from ph.d program            75\n",
      "             graduated from law school              69\n",
      "             dropped out of college/university      66\n",
      "             working on ph.d program                66\n",
      "             graduated from space camp              53\n",
      "             dropped out of space camp              47\n",
      "             college/university                     46\n",
      "             graduated from med school              31\n",
      "             working on space camp                  30\n",
      "             two-year college                       23\n",
      "             working on law school                  16\n",
      "             working on med school                  14\n",
      "             dropped out of two-year college        13\n",
      "             dropped out of ph.d program            12\n",
      "             masters program                        11\n",
      "             working on high school                 11\n",
      "             dropped out of masters program          6\n",
      "             high school                             6\n",
      "             space camp                              5\n",
      "             dropped out of high school              4\n",
      "             dropped out of law school               2\n",
      "capricorn    graduated from college/university    1447\n",
      "             graduated from masters program        539\n",
      "             working on college/university         386\n",
      "             working on masters program            121\n",
      "             graduated from two-year college       102\n",
      "             graduated from high school             92\n",
      "             working on two-year college            83\n",
      "             graduated from law school              79\n",
      "             graduated from ph.d program            58\n",
      "             dropped out of college/university      47\n",
      "             working on ph.d program                41\n",
      "             college/university                     38\n",
      "             graduated from space camp              37\n",
      "             working on space camp                  30\n",
      "             dropped out of space camp              27\n",
      "             graduated from med school              24\n",
      "             two-year college                       17\n",
      "             working on law school                  14\n",
      "             working on med school                  14\n",
      "             dropped out of two-year college        10\n",
      "             dropped out of high school              8\n",
      "             dropped out of masters program          8\n",
      "             high school                             7\n",
      "             dropped out of ph.d program             4\n",
      "             ph.d program                            3\n",
      "             space camp                              3\n",
      "             working on high school                  3\n",
      "             masters program                         2\n",
      "             dropped out of law school               1\n",
      "gemini       graduated from college/university    1790\n",
      "             graduated from masters program        627\n",
      "             working on college/university         460\n",
      "             graduated from two-year college       140\n",
      "             graduated from high school            125\n",
      "             working on masters program            115\n",
      "             working on two-year college            93\n",
      "             dropped out of college/university      86\n",
      "             graduated from law school              83\n",
      "             graduated from ph.d program            70\n",
      "             working on ph.d program                54\n",
      "             graduated from space camp              53\n",
      "             college/university                     49\n",
      "             dropped out of space camp              39\n",
      "             working on space camp                  37\n",
      "             graduated from med school              33\n",
      "             dropped out of two-year college        30\n",
      "             working on law school                  22\n",
      "             two-year college                       18\n",
      "             dropped out of high school             12\n",
      "             dropped out of masters program          9\n",
      "             working on med school                   7\n",
      "             masters program                         5\n",
      "             space camp                              5\n",
      "             working on high school                  5\n",
      "             dropped out of ph.d program             4\n",
      "             high school                             4\n",
      "             ph.d program                            4\n",
      "             dropped out of law school               3\n",
      "             law school                              1\n",
      "leo          graduated from college/university    1775\n",
      "             graduated from masters program        605\n",
      "             working on college/university         487\n",
      "             graduated from two-year college       130\n",
      "             graduated from high school            129\n",
      "             working on masters program            118\n",
      "             working on two-year college            92\n",
      "             graduated from ph.d program            83\n",
      "             graduated from law school              80\n",
      "             dropped out of college/university      75\n",
      "             college/university                     63\n",
      "             working on ph.d program                58\n",
      "             graduated from space camp              56\n",
      "             dropped out of space camp              44\n",
      "             working on space camp                  43\n",
      "             working on law school                  24\n",
      "             graduated from med school              23\n",
      "             two-year college                       19\n",
      "             working on med school                  15\n",
      "             dropped out of two-year college        14\n",
      "             dropped out of ph.d program            10\n",
      "             working on high school                  9\n",
      "             dropped out of high school              8\n",
      "             high school                             8\n",
      "             masters program                         7\n",
      "             dropped out of masters program          6\n",
      "             space camp                              6\n",
      "             ph.d program                            3\n",
      "             law school                              2\n",
      "             dropped out of law school               1\n",
      "libra        graduated from college/university    1741\n",
      "             graduated from masters program        590\n",
      "             working on college/university         447\n",
      "             graduated from two-year college       134\n",
      "             working on masters program            126\n",
      "             graduated from high school            116\n",
      "             working on two-year college            88\n",
      "             graduated from law school              81\n",
      "             dropped out of college/university      74\n",
      "             graduated from ph.d program            73\n",
      "             graduated from space camp              57\n",
      "             working on ph.d program                49\n",
      "             college/university                     48\n",
      "             dropped out of space camp              40\n",
      "             working on space camp                  37\n",
      "             graduated from med school              31\n",
      "             working on med school                  20\n",
      "             two-year college                       17\n",
      "             working on law school                  11\n",
      "             dropped out of two-year college        10\n",
      "             working on high school                 10\n",
      "             dropped out of masters program          8\n",
      "             masters program                         7\n",
      "             dropped out of ph.d program             6\n",
      "             high school                             4\n",
      "             space camp                              4\n",
      "             dropped out of high school              3\n",
      "             dropped out of law school               2\n",
      "             law school                              2\n",
      "pisces       graduated from college/university    1583\n",
      "             graduated from masters program        605\n",
      "             working on college/university         393\n",
      "             working on masters program            122\n",
      "             graduated from two-year college       117\n",
      "             graduated from high school             98\n",
      "             dropped out of college/university      96\n",
      "             graduated from ph.d program            90\n",
      "             working on two-year college            71\n",
      "             college/university                     59\n",
      "             working on ph.d program                59\n",
      "             graduated from law school              58\n",
      "             dropped out of space camp              44\n",
      "             working on space camp                  42\n",
      "             graduated from space camp              41\n",
      "             graduated from med school              27\n",
      "             working on law school                  17\n",
      "             dropped out of two-year college        12\n",
      "             working on med school                  11\n",
      "             working on high school                 10\n",
      "             two-year college                        9\n",
      "             dropped out of masters program          8\n",
      "             dropped out of high school              6\n",
      "             dropped out of ph.d program             6\n",
      "             high school                             6\n",
      "             masters program                         4\n",
      "             dropped out of law school               2\n",
      "             ph.d program                            2\n",
      "             space camp                              2\n",
      "             dropped out of med school               1\n",
      "             med school                              1\n",
      "sagittarius  graduated from college/university    1586\n",
      "             graduated from masters program        608\n",
      "             working on college/university         433\n",
      "             working on masters program            116\n",
      "             graduated from two-year college       108\n",
      "             graduated from high school            101\n",
      "             graduated from law school              73\n",
      "             working on two-year college            71\n",
      "             dropped out of college/university      70\n",
      "             working on ph.d program                60\n",
      "             graduated from ph.d program            55\n",
      "             college/university                     49\n",
      "             graduated from space camp              43\n",
      "             dropped out of space camp              39\n",
      "             working on space camp                  39\n",
      "             graduated from med school              28\n",
      "             working on med school                  20\n",
      "             working on law school                  19\n",
      "             two-year college                       17\n",
      "             dropped out of two-year college        14\n",
      "             dropped out of masters program         13\n",
      "             dropped out of high school              8\n",
      "             dropped out of ph.d program             8\n",
      "             high school                             8\n",
      "             masters program                         7\n",
      "             working on high school                  6\n",
      "             space camp                              5\n",
      "             law school                              2\n",
      "             ph.d program                            2\n",
      "             dropped out of med school               1\n",
      "             med school                              1\n",
      "scorpio      graduated from college/university    1634\n",
      "             graduated from masters program        642\n",
      "             working on college/university         395\n",
      "             working on masters program            135\n",
      "             graduated from two-year college       114\n",
      "             graduated from high school             88\n",
      "             dropped out of college/university      85\n",
      "             working on two-year college            85\n",
      "             graduated from ph.d program            82\n",
      "             graduated from law school              77\n",
      "             college/university                     69\n",
      "             working on ph.d program                62\n",
      "             graduated from space camp              61\n",
      "             dropped out of space camp              35\n",
      "             working on space camp                  35\n",
      "             graduated from med school              31\n",
      "             dropped out of two-year college        20\n",
      "             two-year college                       20\n",
      "             working on law school                  16\n",
      "             working on med school                  16\n",
      "             dropped out of high school             11\n",
      "             dropped out of masters program         11\n",
      "             high school                            11\n",
      "             dropped out of ph.d program            10\n",
      "             working on high school                  6\n",
      "             space camp                              5\n",
      "             masters program                         3\n",
      "             law school                              2\n",
      "             med school                              2\n",
      "             ph.d program                            2\n",
      "             dropped out of law school               1\n",
      "taurus       graduated from college/university    1745\n",
      "             graduated from masters program        536\n",
      "             working on college/university         448\n",
      "             graduated from high school            142\n",
      "             working on masters program            125\n",
      "             graduated from two-year college       108\n",
      "             working on two-year college            92\n",
      "             dropped out of college/university      73\n",
      "             graduated from ph.d program            72\n",
      "             graduated from law school              71\n",
      "             working on ph.d program                59\n",
      "             college/university                     52\n",
      "             graduated from space camp              52\n",
      "             dropped out of space camp              35\n",
      "             working on space camp                  27\n",
      "             graduated from med school              22\n",
      "             working on law school                  22\n",
      "             dropped out of two-year college        18\n",
      "             two-year college                       17\n",
      "             working on med school                  15\n",
      "             dropped out of high school             11\n",
      "             dropped out of masters program         10\n",
      "             high school                             9\n",
      "             dropped out of ph.d program             7\n",
      "             masters program                         6\n",
      "             working on high school                  5\n",
      "             space camp                              4\n",
      "             law school                              1\n",
      "virgo        graduated from college/university    1744\n",
      "             graduated from masters program        602\n",
      "             working on college/university         405\n",
      "             graduated from high school            127\n",
      "             working on masters program            116\n",
      "             graduated from two-year college       114\n",
      "             working on two-year college            87\n",
      "             dropped out of college/university      86\n",
      "             graduated from law school              76\n",
      "             graduated from ph.d program            64\n",
      "             working on ph.d program                58\n",
      "             graduated from space camp              47\n",
      "             college/university                     43\n",
      "             dropped out of space camp              39\n",
      "             working on space camp                  34\n",
      "             graduated from med school              27\n",
      "             working on law school                  21\n",
      "             two-year college                       19\n",
      "             dropped out of two-year college        16\n",
      "             dropped out of masters program         12\n",
      "             dropped out of ph.d program            10\n",
      "             working on med school                  10\n",
      "             working on high school                  8\n",
      "             dropped out of high school              7\n",
      "             space camp                              5\n",
      "             masters program                         4\n",
      "             high school                             3\n",
      "             dropped out of med school               2\n",
      "             dropped out of law school               1\n"
     ]
    }
   ],
   "source": [
    "# How many people have filled out their essays?\n",
    "\n",
    "essays_columns = [\"essay0\", \"essay1\", \"essay2\", \"essay3\", \"essay4\", \"essay5\", \"essay6\", \"essay7\", \"essay8\", \"essay9\"]\n",
    "essays_null = df[essays_columns].isnull().sum()\n",
    "\n",
    "\n",
    "print(f\"The number of essays that are not completed are:\\n{essays_null}\")\n",
    "print(f\"The total of essays without being filled is {essays_null.sum()} that is the {essays_null.sum() * 100 / (len(df) * len(essays_columns)):.2f}%\")\n",
    "\n",
    "# How many people have at least on essay filled out\n",
    "at_least_one_essay = df[essays_columns].notnull().any(axis=1).sum()\n",
    "\n",
    "print(f\"At least {at_least_one_essay } have 1 essay filled out\\n\")\n",
    "\n",
    "# How many people filled out all the essays?\n",
    "filled_all_essays = df[essays_columns].notnull().all(axis=1).sum()\n",
    "\n",
    "print(f\"The total number of people that filled out all the essays is {filled_all_essays}\")\n",
    "\n",
    "# Which essays are the most/least completed?\n",
    "essays_most_completed = df[essays_columns].notnull().sum().idxmax()\n",
    "number_of_essays_completed_max = df[essays_columns].notnull().sum().max()\n",
    "\n",
    "print(f\"The essay {essays_most_completed} is the most completed one with {number_of_essays_completed_max}\\n\")\n",
    "\n",
    "least_completed_essay = df[essays_columns].notnull().sum().idxmin()\n",
    "number_of_essays_completed_min = df[essays_columns].notnull().sum().min()\n",
    "\n",
    "print(f\"The essay {least_completed_essay} is the least completed one with {number_of_essays_completed_min}\\n\")\n",
    "\n",
    "# Ranked essays\n",
    "top_down_sorted_essays = df[essays_columns].notnull().sum().sort_values(ascending=False)\n",
    "\n",
    "print(f\"Essays with most fields filled in descending order:\\n{top_down_sorted_essays}\")\n",
    "\n",
    "# Are there patterns in which zodiac signs write longer/shorter essays?\n",
    "cleaned_zodiac_fields = df[\"sign\"].str.split(' ').str[0]\n",
    "df[\"new_zodiac\"] = cleaned_zodiac_fields\n",
    "group_by_zodiac = df.groupby('sign')[essays_columns].count()\n",
    "\n",
    "print(\"Relation of essays per sign: \", \"\\n\", df.groupby(\"new_zodiac\")[essays_columns].count())\n",
    "\n",
    "\n",
    "# Count the total number of people per zodiac sign\n",
    "people_per_sign = df.groupby(\"new_zodiac\").size()\n",
    "print(f\"The number of people per each sign: \\n {people_per_sign}\", \"\\n\")\n",
    "\n",
    "# Which signs tend to write more essays?\n",
    "essays_per_sign = df.groupby(\"new_zodiac\")[essays_columns].count().sum(axis=1).sort_values(ascending=False)\n",
    "print(\"The number of essays per sign in descending order is:\", essays_per_sign, \"\\n\")\n",
    "\n",
    "print(\"The average number of essays per person by sign is:\", \"\\n\",(essays_per_sign / people_per_sign).sort_values(ascending=False))\n",
    "# Do certain lifestyle choices correlate with specific signs?\n",
    "# Let's try drinks\n",
    "drink_desperately = (df['drinks'] == 'desperately').sum()\n",
    "print(\"Number of person per sign that drink desperately:\", drink_desperately)\n",
    "print(df[\"drinks\"].unique())\n",
    "dont_drink = df[(df[\"drinks\"] == 'not at all')].groupby(\"new_zodiac\").size().sort_values(ascending=False)\n",
    "print(\"Dont drink:\", dont_drink)\n",
    "drink_alot = df[(df[\"drinks\"] == 'desperately')].groupby(\"new_zodiac\").size().sort_values(ascending=False)\n",
    "print(\"Drink a lot:\", drink_alot)\n",
    "\n",
    "# Drugs\n",
    "# Unique values in drugs\n",
    "never_drugs = df[(df[\"drugs\"] == \"never\")].groupby(\"new_zodiac\").size().sort_values(ascending=False)\n",
    "print(\"people who never do drugs:\", never_drugs)\n",
    "often_drugs = df[(df[\"drugs\"] == \"often\")].groupby(\"new_zodiac\").size().sort_values(ascending=False)\n",
    "print(\"People that often do drugs:\", often_drugs)\n",
    "\n",
    "print(df.columns.tolist())\n",
    "# print(df[\"education\"].unique())\n",
    "\n",
    "university_and_sign = df[(df[\"education\"] == 'graduated from ph.d program')].groupby(\"new_zodiac\").size()\n",
    "print(\"PhD and sign:\", university_and_sign)\n",
    "sign_education = df.groupby(\"new_zodiac\")[\"education\"].value_counts().to_string()\n",
    "print(\"Relationship between sign and education:\", sign_education)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per essay missing counts: essay0     5488\n",
      "essay1     7572\n",
      "essay2     9638\n",
      "essay3    11476\n",
      "essay4    10537\n",
      "essay5    10850\n",
      "essay6    13771\n",
      "essay7    12451\n",
      "essay8    19225\n",
      "essay9    12603\n",
      "dtype: int64\n",
      "Number of NaN in all essays: 113611\n",
      "Rown with at least one essay: 57822\n",
      "Number of rows with all essays empty: 2124\n",
      "In percentage: 3.543188869982985 %\n",
      "Everything is correct\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# === NLP: Zodiac vs Essay Content (Plan) ===\n",
    "# 1) Select text sources\n",
    "#    - Decide which essay columns to use (e.g., essay0..essay9, start simple with essay0)\n",
    "#    - Drop rows where all chosen essays are null\n",
    "# Drop all the rown where all the essays are empty\n",
    "df[essays_columns] = df[essays_columns].replace(r'^\\s*$', np.nan, regex=True)\n",
    "\n",
    "per_essay_missing_counts = df[essays_columns].isna().sum()\n",
    "\n",
    "total_nan_all_essays = per_essay_missing_counts.sum()\n",
    "rows_at_least_one_essay = df[essays_columns].notna().any(axis=1).sum()\n",
    "rows_all_essays_null = df[essays_columns].isna().all(axis=1).sum()\n",
    "print(\"Per essay missing counts:\", per_essay_missing_counts)\n",
    "print(\"Number of NaN in all essays:\", total_nan_all_essays)\n",
    "print(\"Rown with at least one essay:\", rows_at_least_one_essay)\n",
    "print(\"Number of rows with all essays empty:\", rows_all_essays_null)\n",
    "print(\"In percentage:\", (rows_all_essays_null / len(df)) * 100,\"%\")\n",
    "\n",
    "if rows_at_least_one_essay + rows_all_essays_null == len(df):\n",
    "    print(\"Everything is correct\")\n",
    "else:\n",
    "    print(\"Something is wrong\")\n",
    "#normalize_nan_row = df[essays_columns].replace(\"\", \"NaN\")\n",
    "\n",
    "#rows_with_all_essays_available = df[essays_columns].dropna(how=\"all\")\n",
    "\n",
    "# 2) Build target and text\n",
    "#    - Target: 'new_zodiac'\n",
    "#    - Text: concatenate selected essays into a single string per user (optional)\n",
    "\n",
    "# 3) Create quick QA checks\n",
    "#    - Inspect sample texts (head), check missing rates, average length, basic stats\n",
    "\n",
    "# 4) Text cleaning (progressively, keep it simple first)\n",
    "#    - Lowercase\n",
    "#    - Remove URLs, HTML, punctuation, numbers (optional)\n",
    "#    - Normalize whitespace\n",
    "#    - (Optional) Remove stopwords, apply lemmatization\n",
    "\n",
    "# 5) Baseline features\n",
    "#    - Simple numeric features: text length (chars), word count, unique word ratio\n",
    "#    - Bag-of-Words or TF-IDF features using scikit-learn\n",
    "\n",
    "# 6) Train/validation split\n",
    "#    - Stratify by 'new_zodiac' to keep class balance consistent\n",
    "\n",
    "# 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Step 3: Define Your Research Question\n",
    "\n",
    "Before diving into analysis, it's important to define what you want to learn from this data. Consider questions like:\n",
    "\n",
    "**Possible Research Questions:**\n",
    "- Can we predict someone's age based on their profile information?\n",
    "- What factors influence the length of someone's essay responses?\n",
    "- Are there patterns in how people describe themselves in their profiles?\n",
    "- Maybe classify Zodiac signs using drinking, smoking, drugs, and essays as the features? üßê\n",
    "- Can we predict compatibility based on profile characteristics?\n",
    "- What are the most common personality traits mentioned in profiles?\n",
    "\n",
    "**üí° Hint:** Choose a question that interests you and can be answered with machine learning!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your research question here\n",
    "research_question = \"YOUR RESEARCH QUESTION HERE\"\n",
    "\n",
    "print(f\"üî¨ Research Question: {research_question}\")\n",
    "print(\"\\nüí≠ Think about:\")\n",
    "print(\"- What type of machine learning problem is this? (classification, regression, clustering)\")\n",
    "print(\"- What features will you use as predictors?\")\n",
    "print(\"- What will be your target variable?\")\n",
    "print(\"- How will you measure success?\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìà Step 4: Exploratory Data Analysis (EDA)\n",
    "\n",
    "Now let's dive deeper into the data with visualizations and statistical analysis:\n",
    "\n",
    "**EDA Goals:**\n",
    "- Create visualizations to understand data distributions\n",
    "- Identify relationships between variables\n",
    "- Look for patterns and trends\n",
    "- Generate insights that inform your modeling approach\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualizations for key variables\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Age distribution\n",
    "if 'age' in df.columns:\n",
    "    axes[0, 0].hist(df['age'].dropna(), bins=30, alpha=0.7, color='skyblue')\n",
    "    axes[0, 0].set_title('Age Distribution')\n",
    "    axes[0, 0].set_xlabel('Age')\n",
    "    axes[0, 0].set_ylabel('Frequency')\n",
    "\n",
    "# Gender distribution\n",
    "if 'sex' in df.columns:\n",
    "    gender_counts = df['sex'].value_counts()\n",
    "    axes[0, 1].pie(gender_counts.values, labels=gender_counts.index, autopct='%1.1f%%')\n",
    "    axes[0, 1].set_title('Gender Distribution')\n",
    "\n",
    "# Height distribution (if available)\n",
    "if 'height' in df.columns:\n",
    "    axes[1, 0].hist(df['height'].dropna(), bins=30, alpha=0.7, color='lightgreen')\n",
    "    axes[1, 0].set_title('Height Distribution')\n",
    "    axes[1, 0].set_xlabel('Height')\n",
    "    axes[1, 0].set_ylabel('Frequency')\n",
    "\n",
    "# Body type distribution\n",
    "if 'body_type' in df.columns:\n",
    "    body_type_counts = df['body_type'].value_counts().head(8)\n",
    "    axes[1, 1].bar(range(len(body_type_counts)), body_type_counts.values)\n",
    "    axes[1, 1].set_title('Body Type Distribution')\n",
    "    axes[1, 1].set_xticks(range(len(body_type_counts)))\n",
    "    axes[1, 1].set_xticklabels(body_type_counts.index, rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"üìä EDA Visualizations created!\")\n",
    "print(\"üí° What patterns do you notice? What insights can you draw?\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß Step 5: Data Preprocessing\n",
    "\n",
    "Before building models, we need to clean and prepare our data:\n",
    "\n",
    "**Preprocessing Tasks:**\n",
    "- Handle missing values\n",
    "- Encode categorical variables\n",
    "- Scale numerical features\n",
    "- Create new features if needed\n",
    "- Split data into training and testing sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing template\n",
    "# Modify this based on your research question and chosen features\n",
    "\n",
    "# Select features for your model (customize based on your research question)\n",
    "# Example: predicting age based on other profile characteristics\n",
    "feature_columns = ['height', 'body_type', 'diet', 'drinks', 'drugs', 'education', 'job', 'income']\n",
    "target_column = 'age'  # Change this based on your research question\n",
    "\n",
    "# Create a copy for preprocessing\n",
    "df_processed = df.copy()\n",
    "\n",
    "# Handle missing values (choose strategy based on your data)\n",
    "# Option 1: Drop rows with missing values\n",
    "# df_processed = df_processed.dropna(subset=feature_columns + [target_column])\n",
    "\n",
    "# Option 2: Fill missing values\n",
    "# df_processed[feature_columns] = df_processed[feature_columns].fillna('Unknown')\n",
    "\n",
    "print(\"üîß Preprocessing steps:\")\n",
    "print(f\"üìä Original dataset shape: {df.shape}\")\n",
    "print(f\"üéØ Target variable: {target_column}\")\n",
    "print(f\"üìã Feature columns: {feature_columns}\")\n",
    "print(f\"üîç Missing values in features: {df_processed[feature_columns].isnull().sum().sum()}\")\n",
    "print(f\"üîç Missing values in target: {df_processed[target_column].isnull().sum()}\")\n",
    "\n",
    "# Split into features and target\n",
    "X = df_processed[feature_columns]\n",
    "y = df_processed[target_column]\n",
    "\n",
    "print(f\"\\nüìà Features shape: {X.shape}\")\n",
    "print(f\"üìà Target shape: {y.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü§ñ Step 6: Build and Train Machine Learning Models\n",
    "\n",
    "Now it's time to build your machine learning model! Choose the appropriate algorithm based on your research question:\n",
    "\n",
    "**Model Types:**\n",
    "- **Classification**: Predicting categories (e.g., gender, body_type)\n",
    "- **Regression**: Predicting numerical values (e.g., age, income)\n",
    "- **Clustering**: Finding groups in data (e.g., personality types)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Machine Learning Model Template\n",
    "# Customize this based on your research question\n",
    "\n",
    "# Encode categorical variables\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Identify categorical columns\n",
    "categorical_cols = X.select_dtypes(include=['object']).columns\n",
    "numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "print(f\"üè∑Ô∏è Categorical columns: {list(categorical_cols)}\")\n",
    "print(f\"üî¢ Numerical columns: {list(numerical_cols)}\")\n",
    "\n",
    "# Create preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_cols),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"üìä Training set size: {X_train.shape[0]}\")\n",
    "print(f\"üìä Test set size: {X_test.shape[0]}\")\n",
    "\n",
    "# Example: Random Forest Classifier (modify based on your problem type)\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Create a pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', model)\n",
    "])\n",
    "\n",
    "print(\"ü§ñ Model pipeline created!\")\n",
    "print(\"üí° Next: Fit the model and evaluate performance\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Step 7: Model Training and Evaluation\n",
    "\n",
    "Train your model and evaluate its performance:\n",
    "\n",
    "**Evaluation Metrics:**\n",
    "- **Classification**: Accuracy, Precision, Recall, F1-Score\n",
    "- **Regression**: Mean Absolute Error, Mean Squared Error, R¬≤\n",
    "- **Clustering**: Silhouette Score, Inertia\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate the model\n",
    "print(\"üöÄ Training the model...\")\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "print(\"‚úÖ Model training completed!\")\n",
    "\n",
    "# Make predictions\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"\\nüìä Model Performance:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# For classification problems\n",
    "if pipeline.named_steps['classifier'].__class__.__name__ in ['RandomForestClassifier', 'LogisticRegression', 'SVC']:\n",
    "    from sklearn.metrics import accuracy_score, classification_report\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"üéØ Accuracy: {accuracy:.3f}\")\n",
    "    print(\"\\nüìã Detailed Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.show()\n",
    "\n",
    "# For regression problems\n",
    "elif pipeline.named_steps['classifier'].__class__.__name__ in ['RandomForestRegressor', 'LinearRegression']:\n",
    "    from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"üìè Mean Absolute Error: {mae:.3f}\")\n",
    "    print(f\"üìè Mean Squared Error: {mse:.3f}\")\n",
    "    print(f\"üìè R¬≤ Score: {r2:.3f}\")\n",
    "    \n",
    "    # Prediction vs Actual plot\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(y_test, y_pred, alpha=0.5)\n",
    "    plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "    plt.xlabel('Actual Values')\n",
    "    plt.ylabel('Predicted Values')\n",
    "    plt.title('Predicted vs Actual Values')\n",
    "    plt.show()\n",
    "\n",
    "print(\"\\nüéâ Model evaluation completed!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìà Step 8: Feature Importance and Model Interpretation\n",
    "\n",
    "Understanding which features are most important for your model's predictions:\n",
    "\n",
    "**Interpretation Goals:**\n",
    "- Identify the most influential features\n",
    "- Understand how your model makes decisions\n",
    "- Generate insights about the data\n",
    "- Validate your model's logic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance analysis\n",
    "if hasattr(pipeline.named_steps['classifier'], 'feature_importances_'):\n",
    "    # Get feature names after preprocessing\n",
    "    feature_names = []\n",
    "    \n",
    "    # Add numerical feature names\n",
    "    if len(numerical_cols) > 0:\n",
    "        feature_names.extend(numerical_cols)\n",
    "    \n",
    "    # Add categorical feature names (after one-hot encoding)\n",
    "    if len(categorical_cols) > 0:\n",
    "        # Get the one-hot encoded feature names\n",
    "        ohe = pipeline.named_steps['preprocessor'].named_transformers_['cat']\n",
    "        cat_feature_names = ohe.get_feature_names_out(categorical_cols)\n",
    "        feature_names.extend(cat_feature_names)\n",
    "    \n",
    "    # Get feature importances\n",
    "    importances = pipeline.named_steps['classifier'].feature_importances_\n",
    "    \n",
    "    # Create feature importance dataframe\n",
    "    feature_importance_df = pd.DataFrame({\n",
    "        'feature': feature_names,\n",
    "        'importance': importances\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    # Plot feature importance\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    top_features = feature_importance_df.head(15)\n",
    "    sns.barplot(data=top_features, x='importance', y='feature')\n",
    "    plt.title('Top 15 Most Important Features')\n",
    "    plt.xlabel('Feature Importance')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"üîç Top 10 Most Important Features:\")\n",
    "    print(feature_importance_df.head(10))\n",
    "    \n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è This model doesn't support feature importance analysis.\")\n",
    "    print(\"üí° Try using Random Forest, Gradient Boosting, or other tree-based models for feature importance.\")\n",
    "\n",
    "print(\"\\nüí≠ What do these feature importances tell you about your data?\")\n",
    "print(\"ü§î Are the most important features what you expected?\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìù Step 9: Conclusions and Insights\n",
    "\n",
    "Summarize your findings and draw conclusions from your analysis:\n",
    "\n",
    "**What to Include:**\n",
    "- Key findings from your analysis\n",
    "- Answers to your research question\n",
    "- Limitations of your approach\n",
    "- Suggestions for future work\n",
    "- Business or practical implications\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary and Conclusions\n",
    "print(\"üéØ PROJECT SUMMARY\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(f\"üìä Dataset: OKCupid profiles ({df.shape[0]:,} profiles, {df.shape[1]} features)\")\n",
    "print(f\"üî¨ Research Question: {research_question}\")\n",
    "print(f\"ü§ñ Model Used: {pipeline.named_steps['classifier'].__class__.__name__}\")\n",
    "\n",
    "# Add your conclusions here\n",
    "print(\"\\nüìã KEY FINDINGS:\")\n",
    "print(\"‚Ä¢ [Add your key findings here]\")\n",
    "print(\"‚Ä¢ [What patterns did you discover?]\")\n",
    "print(\"‚Ä¢ [What surprised you about the data?]\")\n",
    "\n",
    "print(\"\\nüéØ ANSWERS TO RESEARCH QUESTION:\")\n",
    "print(\"‚Ä¢ [How well did your model perform?]\")\n",
    "print(\"‚Ä¢ [What factors are most important?]\")\n",
    "print(\"‚Ä¢ [What insights can you draw?]\")\n",
    "\n",
    "print(\"\\n‚ö†Ô∏è LIMITATIONS:\")\n",
    "print(\"‚Ä¢ [What are the limitations of your analysis?]\")\n",
    "print(\"‚Ä¢ [What assumptions did you make?]\")\n",
    "print(\"‚Ä¢ [What data quality issues affected results?]\")\n",
    "\n",
    "print(\"\\nüöÄ FUTURE WORK:\")\n",
    "print(\"‚Ä¢ [What would you do differently next time?]\")\n",
    "print(\"‚Ä¢ [What additional data would be helpful?]\")\n",
    "print(\"‚Ä¢ [What other models could you try?]\")\n",
    "\n",
    "print(\"\\nüíº PRACTICAL IMPLICATIONS:\")\n",
    "print(\"‚Ä¢ [How could these findings be used in practice?]\")\n",
    "print(\"‚Ä¢ [What recommendations would you make?]\")\n",
    "\n",
    "print(\"\\nüéâ Congratulations on completing your OKCupid analysis!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Codecademy ML",
   "language": "python",
   "name": "codeacademy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
